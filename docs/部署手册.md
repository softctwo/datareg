# 银行重要数据跨境数据管控系统 - 部署手册

## 目录

1. [部署概述](#1-部署概述)
2. [环境准备](#2-环境准备)
3. [系统部署](#3-系统部署)
4. [配置管理](#4-配置管理)
5. [运维监控](#5-运维监控)
6. [故障排除](#6-故障排除)
7. [备份恢复](#7-备份恢复)

---

## 1. 部署概述

### 1.1 部署架构

本系统采用前后端分离的微服务架构，支持多种部署方式：

- **单机部署**：适合开发和测试环境
- **容器化部署**：使用Docker和Docker Compose
- **Kubernetes部署**：适合生产环境
- **云平台部署**：支持主流云平台

### 1.2 系统组件

| 组件 | 技术栈 | 端口 | 说明 |
|------|--------|------|------|
| 前端服务 | React + Nginx | 80/443 | Web界面服务 |
| 后端API | FastAPI + Uvicorn | 8000 | RESTful API服务 |
| 数据库 | PostgreSQL | 5432 | 主数据库 |
| 缓存服务 | Redis | 6379 | 缓存和会话存储 |
| 任务队列 | Celery Worker | - | 异步任务处理 |
| 监控服务 | Prometheus + Grafana | 9090/3001 | 系统监控（可选） |

### 1.3 部署策略

1. **环境隔离**：开发、测试、生产环境分离
2. **渐进式部署**：支持蓝绿部署和滚动更新
3. **自动化运维**：使用脚本和工具自动化部署流程
4. **监控告警**：建立完善的监控和告警机制

---

## 2. 环境准备

### 2.1 硬件要求

#### 2.1.1 最小配置（开发/测试）

| 组件 | CPU | 内存 | 存储 | 网络 |
|------|-----|------|------|------|
| 应用服务器 | 4核 | 8GB | 100GB | 1Gbps |
| 数据库服务器 | 4核 | 8GB | 200GB | 1Gbps |

#### 2.1.2 推荐配置（生产）

| 组件 | CPU | 内存 | 存储 | 网络 |
|------|-----|------|------|------|
| 前端服务器 | 8核 | 16GB | 100GB SSD | 10Gbps |
| 后端服务器 | 16核 | 32GB | 100GB SSD | 10Gbps |
| 数据库服务器 | 16核 | 64GB | 1TB SSD | 10Gbps |
| Redis服务器 | 8核 | 16GB | 100GB SSD | 10Gbps |

### 2.2 软件要求

#### 2.2.1 操作系统

- **推荐**: CentOS 8+, Ubuntu 20.04+, RHEL 8+
- **支持**: Windows Server 2019+, macOS 11+

#### 2.2.2 运行时环境

```bash
# Python环境
Python 3.11+

# Node.js环境
Node.js 18+

# 数据库
PostgreSQL 14+

# 容器环境（可选）
Docker 20.10+
Docker Compose 2.0+

# 容器编排（可选）
Kubernetes 1.24+
```

### 2.3 网络要求

#### 2.3.1 端口配置

```bash
# 必需端口
80          # HTTP访问（前端）
443         # HTTPS访问（前端）
8000        # API服务（后端）
5432        # PostgreSQL数据库
6379        # Redis缓存

# 可选端口
9090        # Prometheus监控
3001        # Grafana监控界面
3000        # 前端开发服务器
```

#### 2.3.2 防火墙配置

```bash
# CentOS/RHEL防火墙配置
sudo firewall-cmd --permanent --add-port=80/tcp
sudo firewall-cmd --permanent --add-port=443/tcp
sudo firewall-cmd --permanent --add-port=8000/tcp
sudo firewall-cmd --permanent --add-port=5432/tcp
sudo firewall-cmd --permanent --add-port=6379/tcp
sudo firewall-cmd --reload

# Ubuntu防火墙配置
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw allow 8000/tcp
sudo ufw allow 5432/tcp
sudo ufw allow 6379/tcp
sudo ufw reload
```

---

## 3. 系统部署

### 3.1 快速部署（推荐）

#### 3.1.1 使用启动脚本

```bash
# 1. 克隆项目代码
git clone https://github.com/your-org/datareg.git
cd datareg

# 2. 给启动脚本添加执行权限
chmod +x start.sh

# 3. 运行启动脚本
./start.sh
```

启动脚本会自动完成：
- 环境检查
- 数据库初始化
- 后端服务启动
- 前端服务启动
- 访问地址显示

#### 3.1.2 启动脚本说明

```bash
#!/bin/bash
# start.sh - 一键启动脚本

echo "正在启动银行重要数据跨境数据管控系统..."

# 检查依赖
check_dependencies() {
    echo "检查系统依赖..."

    # 检查Python
    if ! command -v python3 &> /dev/null; then
        echo "错误: 未找到Python3，请先安装Python 3.11+"
        exit 1
    fi

    # 检查Node.js
    if ! command -v node &> /dev/null; then
        echo "错误: 未找到Node.js，请先安装Node.js 18+"
        exit 1
    fi

    # 检查PostgreSQL
    if ! command -v psql &> /dev/null; then
        echo "警告: 未找到PostgreSQL客户端，请确保PostgreSQL已安装"
    fi

    echo "依赖检查完成"
}

# 初始化数据库
init_database() {
    echo "初始化数据库..."

    cd backend
    python3 create_db.py
    python3 init_db.py
    python3 init_users.py
    python3 init_demo_data.py

    cd ..
    echo "数据库初始化完成"
}

# 启动后端服务
start_backend() {
    echo "启动后端服务..."

    cd backend

    # 安装依赖
    if [ ! -d "venv" ]; then
        python3 -m venv venv
    fi

    source venv/bin/activate
    pip install -r requirements.txt

    # 启动服务
    nohup uvicorn app.main:app --host 0.0.0.0 --port 8000 > ../logs/backend.log 2>&1 &

    cd ..
    echo "后端服务已启动 (端口: 8000)"
}

# 启动前端服务
start_frontend() {
    echo "启动前端服务..."

    cd frontend

    # 安装依赖
    if [ ! -d "node_modules" ]; then
        npm install
    fi

    # 构建生产版本
    npm run build

    # 使用serve启动
    nohup npx serve -s dist -l 3000 > ../logs/frontend.log 2>&1 &

    cd ..
    echo "前端服务已启动 (端口: 3000)"
}

# 主流程
main() {
    # 创建日志目录
    mkdir -p logs

    # 执行部署步骤
    check_dependencies
    init_database
    start_backend
    start_frontend

    echo ""
    echo "=================================="
    echo "系统启动成功！"
    echo "=================================="
    echo "前端地址: http://localhost:3000"
    echo "后端API: http://localhost:8000"
    echo "API文档: http://localhost:8000/api/docs"
    echo ""
    echo "默认用户:"
    echo "  管理员: admin / admin123"
    echo "  测试用户: test / test123"
    echo "=================================="
    echo ""
    echo "查看日志:"
    echo "  后端日志: tail -f logs/backend.log"
    echo "  前端日志: tail -f logs/frontend.log"
    echo ""
    echo "停止系统: ./stop.sh"
}

main
```

### 3.2 手动部署

#### 3.2.1 数据库部署

**安装PostgreSQL**

```bash
# CentOS/RHEL
sudo yum install postgresql postgresql-server postgresql-contrib
sudo postgresql-setup initdb
sudo systemctl enable postgresql
sudo systemctl start postgresql

# Ubuntu
sudo apt update
sudo apt install postgresql postgresql-contrib
sudo systemctl enable postgresql
sudo systemctl start postgresql
```

**创建数据库和用户**

```bash
# 切换到postgres用户
sudo -u postgres psql

# 创建数据库
CREATE DATABASE datareg;

# 创建用户
CREATE USER datareg_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE datareg TO datareg_user;
\q
```

**数据库初始化**

```bash
cd backend

# 创建数据库（如果不存在）
python3 create_db.py

# 初始化表结构
python3 init_db.py

# 创建默认用户
python3 init_users.py

# 创建演示数据（可选）
python3 init_demo_data.py
```

#### 3.2.2 后端部署

**安装Python依赖**

```bash
cd backend

# 创建虚拟环境
python3 -m venv venv

# 激活虚拟环境
source venv/bin/activate  # Linux/macOS
# 或 venv\Scripts\activate  # Windows

# 安装依赖
pip install -r requirements.txt
```

**配置环境变量**

```bash
# 创建.env文件
cat > .env << EOF
# 数据库配置
DATABASE_URL=postgresql://datareg_user:your_password@localhost:5432/datareg

# Redis配置
REDIS_URL=redis://localhost:6379/0

# JWT配置
SECRET_KEY=your-secret-key-here
ACCESS_TOKEN_EXPIRE_MINUTES=30

# 系统配置
DEBUG=false
ENVIRONMENT=production

# 日志配置
LOG_LEVEL=INFO
LOG_FILE=logs/app.log
EOF
```

**启动后端服务**

```bash
# 开发模式
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# 生产模式
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4

# 使用systemd管理（生产）
sudo tee /etc/systemd/system/datareg-backend.service > /dev/null <<EOF
[Unit]
Description=DataReg Backend Service
After=network.target

[Service]
Type=exec
User=datareg
Group=datareg
WorkingDirectory=/opt/datareg/backend
Environment=PATH=/opt/datareg/backend/venv/bin
ExecStart=/opt/datareg/backend/venv/bin/uvicorn app.main:app --host 0.0.0.0 --port 8000
Restart=always

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable datareg-backend
sudo systemctl start datareg-backend
```

#### 3.2.3 前端部署

**安装Node.js依赖**

```bash
cd frontend

# 安装依赖
npm install

# 或使用yarn
yarn install
```

**构建生产版本**

```bash
# 构建生产版本
npm run build

# 或使用yarn
yarn build
```

**部署静态文件**

```bash
# 使用nginx部署
sudo cp -r dist/* /var/www/html/

# 或使用serve部署
npm install -g serve
nohup serve -s dist -l 3000 > ../logs/frontend.log 2>&1 &
```

**Nginx配置**

```nginx
# /etc/nginx/sites-available/datareg
server {
    listen 80;
    server_name your-domain.com;

    # 前端静态文件
    location / {
        root /var/www/html;
        index index.html;
        try_files $uri $uri/ /index.html;
    }

    # API代理
    location /api/ {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # 静态资源缓存
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

### 3.3 容器化部署

#### 3.3.1 Docker部署

**后端Dockerfile**

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# 安装Python依赖
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY . .

# 创建非root用户
RUN useradd --create-home --shell /bin/bash app \
    && chown -R app:app /app
USER app

# 暴露端口
EXPOSE 8000

# 健康检查
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# 启动命令
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**前端Dockerfile**

```dockerfile
# frontend/Dockerfile
FROM node:18-alpine as builder

WORKDIR /app

# 安装依赖
COPY package*.json ./
RUN npm ci --only=production

# 构建应用
COPY . .
RUN npm run build

# 生产镜像
FROM nginx:alpine

# 复制构建结果
COPY --from=builder /app/dist /usr/share/nginx/html

# 复制nginx配置
COPY nginx.conf /etc/nginx/nginx.conf

# 健康检查
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD wget --no-verbose --tries=1 --spider http://localhost/ || exit 1

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

**Docker Compose**

```yaml
# docker-compose.yml
version: '3.8'

services:
  db:
    image: postgres:14
    container_name: datareg-db
    environment:
      POSTGRES_DB: datareg
      POSTGRES_USER: datareg_user
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U datareg_user -d datareg"]
      interval: 30s
      timeout: 10s
      retries: 5

  redis:
    image: redis:6-alpine
    container_name: datareg-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: datareg-backend
    environment:
      DATABASE_URL: postgresql://datareg_user:${DB_PASSWORD}@db:5432/datareg
      REDIS_URL: redis://redis:6379/0
      SECRET_KEY: ${SECRET_KEY}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    volumes:
      - ./backend/logs:/app/logs
      - ./backend/uploads:/app/uploads
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: datareg-frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 5

  celery:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: datareg-celery
    command: celery -A app.main.celery worker --loglevel=info
    environment:
      DATABASE_URL: postgresql://datareg_user:${DB_PASSWORD}@db:5432/datareg
      REDIS_URL: redis://redis:6379/0
      SECRET_KEY: ${SECRET_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./backend/logs:/app/logs
    restart: unless-stopped

  celery-beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: datareg-celery-beat
    command: celery -A app.main.celery beat --loglevel=info
    environment:
      DATABASE_URL: postgresql://datareg_user:${DB_PASSWORD}@db:5432/datareg
      REDIS_URL: redis://redis:6379/0
      SECRET_KEY: ${SECRET_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./backend/logs:/app/logs
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
```

**环境变量配置**

```bash
# .env
DB_PASSWORD=your_secure_password
SECRET_KEY=your_secret_key_here
```

**启动容器**

```bash
# 构建并启动所有服务
docker-compose up -d --build

# 查看服务状态
docker-compose ps

# 查看日志
docker-compose logs -f backend
```

### 3.4 Kubernetes部署

#### 3.4.1 命名空间和配置

```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: datareg
  labels:
    name: datareg

---
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: datareg-config
  namespace: datareg
data:
  DATABASE_HOST: "postgres-service"
  DATABASE_PORT: "5432"
  DATABASE_NAME: "datareg"
  REDIS_HOST: "redis-service"
  REDIS_PORT: "6379"
  LOG_LEVEL: "INFO"
```

#### 3.4.2 密钥管理

```yaml
# secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: datareg-secrets
  namespace: datareg
type: Opaque
data:
  DATABASE_URL: <base64-encoded-database-url>
  SECRET_KEY: <base64-encoded-secret-key>
  REDIS_URL: <base64-encoded-redis-url>
```

#### 3.4.3 数据库部署

```yaml
# postgres-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
  namespace: datareg
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:14
        env:
        - name: POSTGRES_DB
          value: datareg
        - name: POSTGRES_USER
          value: datareg_user
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: datareg-secrets
              key: postgres-password
        ports:
        - containerPort: 5432
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
      volumes:
      - name: postgres-storage
        persistentVolumeClaim:
          claimName: postgres-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: postgres-service
  namespace: datareg
spec:
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432
  type: ClusterIP

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
  namespace: datareg
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
```

#### 3.4.4 应用部署

```yaml
# backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: datareg-backend
  namespace: datareg
spec:
  replicas: 3
  selector:
    matchLabels:
      app: datareg-backend
  template:
    metadata:
      labels:
        app: datareg-backend
    spec:
      containers:
      - name: backend
        image: datareg/backend:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: datareg-secrets
              key: DATABASE_URL
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: datareg-secrets
              key: SECRET_KEY
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: datareg-backend-service
  namespace: datareg
spec:
  selector:
    app: datareg-backend
  ports:
  - port: 8000
    targetPort: 8000
  type: ClusterIP
```

#### 3.4.5 Ingress配置

```yaml
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: datareg-ingress
  namespace: datareg
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  tls:
  - hosts:
    - datareg.your-domain.com
    secretName: datareg-tls
  rules:
  - host: datareg.your-domain.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: datareg-backend-service
            port:
              number: 8000
      - path: /
        pathType: Prefix
        backend:
          service:
            name: datareg-frontend-service
            port:
              number: 80
```

---

## 4. 配置管理

### 4.1 环境变量

#### 4.1.1 后端配置

```python
# backend/app/core/config.py
from pydantic_settings import BaseSettings
from typing import Optional

class Settings(BaseSettings):
    # 应用配置
    APP_NAME: str = "银行重要数据跨境数据管控系统"
    VERSION: str = "1.0.0"
    DEBUG: bool = False
    ENVIRONMENT: str = "production"

    # 数据库配置
    DATABASE_URL: str
    DATABASE_POOL_SIZE: int = 10
    DATABASE_MAX_OVERFLOW: int = 20

    # Redis配置
    REDIS_URL: str = "redis://localhost:6379/0"
    REDIS_POOL_SIZE: int = 10

    # JWT配置
    SECRET_KEY: str
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    REFRESH_TOKEN_EXPIRE_DAYS: int = 7

    # 日志配置
    LOG_LEVEL: str = "INFO"
    LOG_FILE: Optional[str] = None
    LOG_MAX_SIZE: int = 100 * 1024 * 1024  # 100MB
    LOG_BACKUP_COUNT: int = 5

    # 合规阈值配置
    PERSONAL_INFO_THRESHOLD: int = 1_000_000
    SENSITIVE_INFO_THRESHOLD: int = 100_000
    THRESHOLD_WARNING_PERCENT: float = 0.95

    # 文件上传配置
    UPLOAD_DIR: str = "uploads"
    MAX_FILE_SIZE: int = 10 * 1024 * 1024  # 10MB
    ALLOWED_EXTENSIONS: list = [".pdf", ".doc", ".docx", ".xls", ".xlsx"]

    # 邮件配置（可选）
    SMTP_TLS: bool = True
    SMTP_PORT: Optional[int] = None
    SMTP_HOST: Optional[str] = None
    SMTP_USER: Optional[str] = None
    SMTP_PASSWORD: Optional[str] = None
    EMAILS_FROM_EMAIL: Optional[str] = None
    EMAILS_FROM_NAME: Optional[str] = None

    # 监控配置
    ENABLE_METRICS: bool = True
    METRICS_PORT: int = 9090

    class Config:
        env_file = ".env"
        case_sensitive = True

settings = Settings()
```

#### 4.1.2 环境变量文件

```bash
# .env.production
# 应用配置
APP_NAME=银行重要数据跨境数据管控系统
VERSION=1.0.0
DEBUG=false
ENVIRONMENT=production

# 数据库配置
DATABASE_URL=postgresql://user:password@localhost:5432/datareg
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=40

# Redis配置
REDIS_URL=redis://localhost:6379/0
REDIS_POOL_SIZE=20

# JWT配置
SECRET_KEY=your-very-secure-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# 日志配置
LOG_LEVEL=INFO
LOG_FILE=/var/log/datareg/app.log
LOG_MAX_SIZE=104857600
LOG_BACKUP_COUNT=10

# 合规阈值配置
PERSONAL_INFO_THRESHOLD=1000000
SENSITIVE_INFO_THRESHOLD=100000
THRESHOLD_WARNING_PERCENT=0.95

# 文件上传配置
UPLOAD_DIR=/var/uploads/datareg
MAX_FILE_SIZE=10485760
ALLOWED_EXTENSIONS=.pdf,.doc,.docx,.xls,.xlsx

# 邮件配置
SMTP_TLS=true
SMTP_PORT=587
SMTP_HOST=smtp.gmail.com
SMTP_USER=datareg@yourbank.com
SMTP_PASSWORD=your-email-password
EMAILS_FROM_EMAIL=datareg@yourbank.com
EMAILS_FROM_NAME=数据跨境管控系统

# 监控配置
ENABLE_METRICS=true
METRICS_PORT=9090
```

### 4.2 数据库配置

#### 4.2.1 PostgreSQL优化配置

```postgresql
# postgresql.conf 关键配置

# 内存配置
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 4MB
maintenance_work_mem = 64MB

# 连接配置
max_connections = 200
listen_addresses = '*'
port = 5432

# 日志配置
log_destination = 'stderr'
logging_collector = 'stderr'
log_directory = 'pg_log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_rotation_age = '1d'
log_rotation_size = '100MB'
log_min_duration_statement = '1000ms'
log_checkpoints = 'on'
log_connections = 'on'
log_disconnections = 'on'
log_lock_waits = 'on'

# 性能配置
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 1000
random_page_cost = 1.1
effective_io_concurrency = 200
```

#### 4.2.2 连接池配置

```python
# backend/app/core/database.py
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool
from app.core.config import settings

engine = create_engine(
    settings.DATABASE_URL,
    poolclass=QueuePool,
    pool_size=settings.DATABASE_POOL_SIZE,
    max_overflow=settings.DATABASE_MAX_OVERFLOW,
    pool_pre_ping=True,
    pool_recycle=3600,
    echo=settings.DEBUG
)
```

### 4.3 缓存配置

#### 4.3.1 Redis配置

```redis
# redis.conf 关键配置

# 内存配置
maxmemory 2gb
maxmemory-policy allkeys-lru

# 持久化配置
save 900 1
save 300 10
save 60 10000

# 日志配置
loglevel notice
logfile /var/log/redis/redis.log

# 网络配置
port 6379
bind 0.0.0.0
timeout 300

# 安全配置
requirepass your-redis-password
rename-command FLUSHDB ""
rename-command FLUSHALL ""
```

#### 4.3.2 连接池配置

```python
# backend/app/core/redis.py
import redis
from app.core.config import settings

redis_pool = redis.ConnectionPool(
    host=settings.REDIS_HOST,
    port=settings.REDIS_PORT,
    db=settings.REDIS_DB,
    password=settings.REDIS_PASSWORD,
    max_connections=settings.REDIS_POOL_SIZE,
    socket_connect_timeout=5,
    socket_timeout=5,
    retry_on_timeout=True
)

redis_client = redis.Redis(connection_pool=redis_pool)
```

### 4.4 安全配置

#### 4.4.1 SSL/TLS配置

**Nginx SSL配置**

```nginx
# /etc/nginx/sites-available/datareg-ssl
server {
    listen 443 ssl http2;
    server_name datareg.your-domain.com;

    # SSL证书配置
    ssl_certificate /etc/ssl/certs/datareg.crt;
    ssl_certificate_key /etc/ssl/private/datareg.key;

    # SSL安全配置
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;

    # HSTS安全头
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Frame-Options DENY always;
    add_header X-Content-Type-Options nosniff always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;

    # 其他配置...
}
```

#### 4.4.2 防火墙配置

```bash
# iptables规则配置
# 清除现有规则
sudo iptables -F
sudo iptables -X
sudo iptables -t nat -F
sudo iptables -t nat -X

# 设置默认策略
sudo iptables -P INPUT DROP
sudo iptables -P FORWARD DROP
sudo iptables -P OUTPUT ACCEPT

# 允许本地回环
sudo iptables -A INPUT -i lo -j ACCEPT

# 允许已建立的连接
sudo iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT

# 允许SSH（管理端口）
sudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT

# 允许HTTP/HTTPS
sudo iptables -A INPUT -p tcp --dport 80 -j ACCEPT
sudo iptables -A INPUT -p tcp --dport 443 -j ACCEPT

# 保存规则
sudo iptables-save > /etc/iptables/rules.v4
```

---

## 5. 运维监控

### 5.1 日志管理

#### 5.1.1 日志配置

```python
# backend/app/core/logging.py
import logging
import logging.config
from pathlib import Path

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'default': {
            'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        },
        'json': {
            'format': '{"timestamp": "%(asctime)s", "level": "%(levelname)s", "logger": "%(name)s", "message": "%(message)s"}',
        },
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'level': 'INFO',
            'formatter': 'default',
            'stream': 'ext://sys.stdout',
        },
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'level': 'INFO',
            'formatter': 'json',
            'filename': settings.LOG_FILE,
            'maxBytes': settings.LOG_MAX_SIZE,
            'backupCount': settings.LOG_BACKUP_COUNT,
            'encoding': 'utf8',
        },
    },
    'loggers': {
        '': {
            'handlers': ['console', 'file'],
            'level': settings.LOG_LEVEL,
            'propagate': False,
        },
        'uvicorn': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': False,
        },
        'sqlalchemy': {
            'handlers': ['file'],
            'level': 'WARNING',
            'propagate': False,
        },
    },
}

logging.config.dictConfig(LOGGING_CONFIG)
```

#### 5.1.2 日志轮转

```bash
# logrotate配置
# /etc/logrotate.d/datareg
/var/log/datareg/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 644 datareg datareg
    postrotate
        systemctl reload datareg-backend
    endscript
}
```

### 5.2 监控指标

#### 5.2.1 应用监控

```python
# backend/app/core/metrics.py
from prometheus_client import Counter, Histogram, Gauge, generate_latest
import time
import functools

# 请求计数器
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

# 请求延迟
REQUEST_LATENCY = Histogram(
    'http_request_duration_seconds',
    'HTTP request latency',
    ['method', 'endpoint']
)

# 活跃用户数
ACTIVE_USERS = Gauge(
    'active_users_total',
    'Number of active users'
)

# 数据库连接数
DB_CONNECTIONS = Gauge(
    'database_connections_active',
    'Active database connections'
)

def track_requests(func):
    """装饰器：跟踪API请求"""
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            REQUEST_COUNT.labels(
                method='POST',  # 根据实际请求方法
                endpoint=func.__name__,
                status='200'
            ).inc()
            return result
        except Exception as e:
            REQUEST_COUNT.labels(
                method='POST',
                endpoint=func.__name__,
                status='500'
            ).inc()
            raise
        finally:
            REQUEST_LATENCY.labels(
                method='POST',
                endpoint=func.__name__
            ).observe(time.time() - start_time)
    return wrapper
```

#### 5.2.2 系统监控

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  - job_name: 'datareg-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: /metrics
    scrape_interval: 10s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:9113']

alerting:
  alertmanagers:
    - static_configs:
      - targets:
        - alertmanager:9093
```

#### 5.2.3 告警规则

```yaml
# alert_rules.yml
groups:
  - name: datareg_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status="5xx"}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, http_request_duration_seconds) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }} seconds"

      - alert: DatabaseDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Database is down"
          description: "PostgreSQL database is not responding"

      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis is down"
          description: "Redis cache server is not responding"
```

### 5.3 健康检查

#### 5.3.1 应用健康检查

```python
# backend/app/api/v1/endpoints/health.py
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.core.redis import redis_client
import redis

router = APIRouter()

@router.get("/health")
async def health_check(db: Session = Depends(get_db)):
    """健康检查接口"""
    health_status = {
        "status": "healthy",
        "timestamp": time.time(),
        "version": "1.0.0",
        "checks": {}
    }

    # 检查数据库连接
    try:
        db.execute("SELECT 1")
        health_status["checks"]["database"] = "healthy"
    except Exception as e:
        health_status["status"] = "unhealthy"
        health_status["checks"]["database"] = f"unhealthy: {str(e)}"

    # 检查Redis连接
    try:
        redis_client.ping()
        health_status["checks"]["redis"] = "healthy"
    except Exception as e:
        health_status["status"] = "unhealthy"
        health_status["checks"]["redis"] = f"unhealthy: {str(e)}"

    # 检查磁盘空间
    disk_usage = shutil.disk_usage("/")
    disk_free_percent = (disk_usage.free / disk_usage.total) * 100
    if disk_free_percent < 10:
        health_status["status"] = "unhealthy"
        health_status["checks"]["disk"] = f"low disk space: {disk_free_percent:.1f}%"
    else:
        health_status["checks"]["disk"] = "healthy"

    status_code = 200 if health_status["status"] == "healthy" else 503
    return JSONResponse(content=health_status, status_code=status_code)
```

#### 5.3.2 系统健康检查

```bash
#!/bin/bash
# health_check.sh - 系统健康检查脚本

check_service_health() {
    local service_name=$1
    local health_url=$2

    echo "检查 $service_name 健康..."

    response=$(curl -s -o /dev/null -w "%{http_code}" "$health_url")

    if [ "$response" = "200" ]; then
        echo "✅ $service_name 健康"
        return 0
    else
        echo "❌ $service_name 不健康 (HTTP $response)"
        return 1
    fi
}

# 检查各个服务
check_service_health "后端API" "http://localhost:8000/health"
check_service_health "前端Web" "http://localhost:80"
check_service_health "数据库" "http://localhost:8000/health/db"
check_service_health "Redis缓存" "http://localhost:8000/health/redis"

# 检查系统资源
echo ""
echo "系统资源使用情况:"

# CPU使用率
cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)
echo "CPU使用率: ${cpu_usage}%"

# 内存使用率
memory_usage=$(free | grep Mem | awk '{printf "%.1f", $3/$2 * 100.0}')
echo "内存使用率: ${memory_usage}%"

# 磁盘使用率
disk_usage=$(df -h / | awk 'NR==2{printf "%s", $5}')
echo "磁盘使用率: $disk_usage"

# 检查日志错误
echo ""
echo "最近错误日志:"
tail -n 10 /var/log/datareg/*.log | grep -i error | tail -n 5
```

### 5.4 性能监控

#### 5.4.1 性能指标收集

```python
# backend/app/core/performance.py
import psutil
import time
from datetime import datetime, timedelta

class PerformanceMonitor:
    def __init__(self):
        self.start_time = time.time()
        self.metrics = {}

    def collect_system_metrics(self):
        """收集系统性能指标"""
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory": {
                "total": psutil.virtual_memory().total,
                "available": psutil.virtual_memory().available,
                "percent": psutil.virtual_memory().percent,
                "used": psutil.virtual_memory().used,
                "free": psutil.virtual_memory().free,
            },
            "disk": {
                "total": psutil.disk_usage('/').total,
                "used": psutil.disk_usage('/').used,
                "free": psutil.disk_usage('/').free,
                "percent": (psutil.disk_usage('/').used / psutil.disk_usage('/').total) * 100,
            },
            "network": {
                "bytes_sent": psutil.net_io_counters().bytes_sent,
                "bytes_recv": psutil.net_io_counters().bytes_recv,
            },
            "uptime": time.time() - self.start_time
        }

    def collect_application_metrics(self):
        """收集应用性能指标"""
        # 这里可以添加特定的应用指标
        return {
            "active_sessions": self.get_active_sessions(),
            "database_connections": self.get_db_connections(),
            "cache_hit_rate": self.get_cache_hit_rate(),
            "error_rate": self.get_error_rate(),
        }
```

---

## 6. 故障排除

### 6.1 常见问题

#### 6.1.1 启动问题

**问题：后端服务启动失败**

```bash
# 检查端口占用
sudo netstat -tlnp | grep :8000

# 检查进程
ps aux | grep uvicorn

# 检查日志
tail -f /var/log/datareg/backend.log

# 解决方案
sudo kill -9 $(sudo lsof -ti:8000)
```

**问题：数据库连接失败**

```bash
# 检查数据库服务
sudo systemctl status postgresql

# 检查连接
psql -h localhost -U datareg_user -d datareg -c "SELECT version();"

# 检查网络
telnet localhost 5432

# 解决方案
sudo systemctl restart postgresql
```

#### 6.1.2 性能问题

**问题：响应时间过长**

```bash
# 检查系统资源
top
htop

# 检查数据库查询
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;

# 检查慢查询
SELECT query, mean_time, calls
FROM pg_stat_statements
WHERE mean_time > 1000
ORDER BY mean_time DESC;
```

**问题：内存不足**

```bash
# 检查内存使用
free -h
ps aux --sort=-%mem | head

# 检查Python进程内存
ps aux | grep python | awk '{sum+=$6} END {print sum/1024/1024 "GB"}'
```

### 6.2 日志分析

#### 6.2.1 错误日志分析

```bash
# 查看最新错误
tail -f /var/log/datareg/error.log | grep ERROR

# 统计错误类型
grep ERROR /var/log/datareg/*.log | awk '{print $5}' | sort | uniq -c | sort -nr

# 查看特定时间段日志
grep "2024-12-23 1[0-2]:" /var/log/datareg/app.log
```

#### 6.2.2 性能日志分析

```bash
# 分析响应时间分布
grep "request duration" /var/log/datareg/app.log | awk '{print $NF}' | sort -n | awk '{a[NR]=$1} END {for(i=1;i<=NR;i++) print a[i]}'

# 统计API调用
grep "POST\|GET\|PUT\|DELETE" /var/log/datareg/access.log | awk '{print $6}' | sort | uniq -c | sort -nr
```

### 6.3 故障恢复

#### 6.3.1 服务重启

```bash
#!/bin/bash
# restart_services.sh

echo "重启数据跨境管控系统服务..."

# 重启后端服务
echo "重启后端服务..."
sudo systemctl restart datareg-backend
sleep 10

# 重启前端服务
echo "重启前端服务..."
sudo systemctl restart nginx
sleep 5

# 重启数据库
echo "重启数据库..."
sudo systemctl restart postgresql
sleep 15

# 检查服务状态
echo "检查服务状态..."
sudo systemctl status datareg-backend
sudo systemctl status nginx
sudo systemctl status postgresql

echo "服务重启完成"
```

#### 6.3.2 数据恢复

```bash
# 数据库备份恢复
#!/bin/bash
# restore_database.sh

BACKUP_FILE=$1
DB_NAME="datareg"

if [ -z "$BACKUP_FILE" ]; then
    echo "使用方法: ./restore_database.sh backup_file.sql"
    exit 1
fi

echo "恢复数据库: $DB_NAME 从文件: $BACKUP_FILE"

# 停止应用服务
sudo systemctl stop datareg-backend

# 恢复数据库
psql -U postgres -d $DB_NAME < $BACKUP_FILE

# 重启服务
sudo systemctl start datareg-backend

echo "数据库恢复完成"
```

---

## 7. 备份恢复

### 7.1 数据备份策略

#### 7.1.1 数据库备份

```bash
#!/bin/bash
# backup_database.sh

BACKUP_DIR="/var/backups/datareg"
DB_NAME="datareg"
DB_USER="datareg_user"
DATE=$(date +%Y%m%d_%H%M%S)

# 创建备份目录
mkdir -p $BACKUP_DIR

# 全量备份
echo "开始全量备份..."
pg_dump -h localhost -U $DB_USER -d $DB_NAME > $BACKUP_DIR/full_backup_$DATE.sql

# 压缩备份文件
gzip $BACKUP_DIR/full_backup_$DATE.sql

# 删除7天前的备份
find $BACKUP_DIR -name "full_backup_*.sql.gz" -mtime +7 -delete

echo "备份完成: $BACKUP_DIR/full_backup_$DATE.sql.gz"
```

#### 7.1.2 增量备份

```bash
#!/bin/bash
# incremental_backup.sh

BACKUP_DIR="/var/backups/datareg"
DB_NAME="datareg"
DB_USER="datareg_user"
DATE=$(date +%Y%m%d_%H%M%S)

# 创建备份目录
mkdir -p $BACKUP_DIR

# 获取最后备份时间
LAST_BACKUP_FILE=$(ls -t $BACKUP_DIR/full_backup_*.sql.gz 2>/dev/null | head -1)

if [ -n "$LAST_BACKUP_FILE" ]; then
    LAST_BACKUP_TIME=$(date -d "$(echo $LAST_BACKUP_FILE | grep -o '[0-9_]\+' | tr '_' ' ' | cut -d' ' -f1,2)" +"%Y-%m-%d %H:%M:%S")

    # 增量备份（使用时间戳条件）
    pg_dump -h localhost -U $DB_USER -d $DB_NAME --where "updated_at > '$LAST_BACKUP_TIME'" > $BACKUP_DIR/incremental_backup_$DATE.sql

    gzip $BACKUP_DIR/incremental_backup_$DATE.sql

    echo "增量备份完成: $BACKUP_DIR/incremental_backup_$DATE.sql.gz"
else
    echo "未找到全量备份文件，执行全量备份"
    ./backup_database.sh
fi
```

#### 7.1.3 自动备份配置

```bash
# 添加到crontab
crontab -e

# 每天凌晨2点执行全量备份
0 2 * * * /opt/datareg/scripts/backup_database.sh

# 每6小时执行增量备份
0 */6 * * * /opt/datareg/scripts/incremental_backup.sh
```

### 7.2 配置文件备份

```bash
#!/bin/bash
# backup_config.sh

CONFIG_DIR="/opt/datareg/config"
BACKUP_DIR="/var/backups/datareg/config"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

# 备份配置文件
tar -czf $BACKUP_DIR/config_$DATE.tar.gz \
    $CONFIG_DIR/.env \
    $CONFIG_DIR/nginx.conf \
    $CONFIG_DIR/redis.conf \
    $CONFIG_DIR/postgresql.conf

# 备份应用代码
tar -czf $BACKUP_DIR/code_$DATE.tar.gz \
    /opt/datareg/backend \
    /opt/datareg/frontend

echo "配置备份完成"
```

### 7.3 灾难恢复

#### 7.3.1 灾难恢复计划

```bash
#!/bin/bash
# disaster_recovery.sh

echo "开始灾难恢复流程..."

# 确认备份文件存在
BACKUP_DIR="/var/backups/datareg"
LATEST_BACKUP=$(ls -t $BACKUP_DIR/full_backup_*.sql.gz | head -1)

if [ -z "$LATEST_BACKUP" ]; then
    echo "错误: 未找到备份文件"
    exit 1
fi

echo "使用备份文件: $LATEST_BACKUP"

# 停止所有服务
echo "停止所有服务..."
sudo systemctl stop datareg-backend
sudo systemctl stop nginx
sudo systemctl stop postgresql

# 备份当前数据（如果存在）
echo "备份当前数据..."
mv /var/lib/postgresql/data /var/lib/postgresql/data.backup.$(date +%Y%m%d)

# 创建新的数据目录
sudo mkdir -p /var/lib/postgresql/data
sudo chown postgres:postgres /var/lib/postgresql/data
sudo chmod 700 /var/lib/postgresql/data

# 初始化数据库
sudo -u postgres initdb -D /var/lib/postgresql/data

# 启动数据库
sudo systemctl start postgresql
sleep 10

# 创建数据库和用户
sudo -u postgres psql << EOF
CREATE DATABASE datareg;
CREATE USER datareg_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE datareg TO datareg_user;
\q

EOF

# 恢复数据
echo "恢复数据库..."
gunzip -c $LATEST_BACKUP | psql -U postgres -d datareg

# 恢复配置文件
echo "恢复配置文件..."
LATEST_CONFIG=$(ls -t $BACKUP_DIR/config_*.tar.gz | head -1)
tar -xzf $LATEST_CONFIG -C /

# 启动所有服务
echo "启动所有服务..."
sudo systemctl start postgresql
sudo systemctl start datareg-backend
sudo systemctl start nginx

# 验证恢复
echo "验证服务状态..."
./health_check.sh

echo "灾难恢复完成"
```

#### 7.3.2 业务连续性

**RTO (恢复时间目标)**: 4小时
**RPO (恢复点目标)**: 1小时

```yaml
# disaster_recovery_plan.yml
recovery_time_objective: 4h
recovery_point_objective: 1h

backup_strategy:
  daily_full_backup: true
  hourly_incremental: true
  offsite_backup: true
  retention_period: 30d

recovery_procedures:
  1. Assess damage and impact
  2. Notify stakeholders
  3. Initiate recovery plan
  4. Restore from latest backup
  5. Verify system integrity
  6. Resume operations
  7. Post-recovery review

contact_persons:
  it_manager: it-manager@bank.com
  dba: dba@bank.com
  system_admin: admin@bank.com
```

---

## 附录

### 附录A：部署检查清单

#### A.1 部署前检查

- [ ] 硬件资源满足要求
- [ ] 操作系统已安装和配置
- [ ] 网络连接正常
- [ ] 防火墙规则已配置
- [ ] SSL证书已获取
- [ ] 域名已解析

#### A.2 软件部署检查

- [ ] 数据库已安装和配置
- [ ] Redis缓存已安装
- [ ] 后端服务已部署
- [ ] 前端应用已部署
- [ ] 监控服务已配置

#### A.3 功能验证检查

- [ ] 用户可以正常登录
- [ ] 数据资产扫描功能正常
- [ ] 场景管理功能正常
- [ ] 审批流程功能正常
- [ ] 监控仪表盘功能正常

### 附录B：配置模板

#### B.1 环境变量模板

```bash
# .env.template
# 复制此文件为.env并修改相应值

# 应用配置
APP_NAME=银行重要数据跨境数据管控系统
VERSION=1.0.0
DEBUG=false
ENVIRONMENT=production

# 数据库配置
DATABASE_URL=postgresql://user:password@localhost:5432/datareg

# Redis配置
REDIS_URL=redis://localhost:6379/0

# JWT配置
SECRET_KEY=your-secret-key-here

# 其他配置...
```

#### B.2 Nginx配置模板

```nginx
# nginx.conf.template
server {
    listen 80;
    server_name your-domain.com;

    # 前端配置
    location / {
        root /var/www/html;
        try_files $uri $uri/ /index.html;
    }

    # API代理配置
    location /api/ {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

### 附录C：联系方式

**技术支持团队**
- 首席工程师：+86-XXX-XXXX-XXXX
- 邮箱：tech-support@bank.com
- 24小时支持热线：400-XXX-XXXX

---

**文档版本**: 1.0
**最后更新**: 2024年12月23日
**编写人**: 张彦龙